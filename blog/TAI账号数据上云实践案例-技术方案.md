# 数据上云技术方案

## 一、背景

账号服务数据主要存储在DCache中，有几十个模块，数据层访问量很大且对耗时敏感。

目前DCache服务在长尾维护阶段，人力不足，问题响应不是很及时。账号的服务质量非常依赖DCache的服务质量，而DCache经常报出超时异常，对我们造成了困扰。 

针对这一情况，准备将账号的数据分几个阶段迁移到云上，能够获得腾讯云较好的支持。另外，期望上云后能提高账号数据层稳定性，提升服务质量。 

数据上云开始之前，已经有一个java版本的dbproxysvc，完成了 XxxAppAccount 这一个模块的上云工作，提供了这个模块所需的selectOne、selectMany、insert、update四个接口，是一个最简版本的上云案例。但是dbproxysvc缺少日志监控，健壮度也不够。为此上半年已经增强了dbproxysvc的监控和日志功能，做全面数据上云之前的先遣调查和实验。

经过调查和实验，分别总结出了dbproxysvc存在的问题和账号服务访问DCache数据的特点：

dbproxysvc存在的问题：

1. 服务节点数太多，承载 XxxAppAccount 一个模块就要消耗190个8c16g pod资源，性能不好导致成本太高。
2. 服务单地部署，缓存单地部署，跨地域访问在高峰时常报超时。
3. 数据写入方案上，写缓存成功就返回，通过消息队列异步写入DB，若缓存或消息队列崩溃有数据丢失风险。

账号服务访问DCache数据的特点：

1. 峰值QPS较高，预估100w左右；

2. 读多写少，读请求占比98%以上；
3. 上游接口往往组合调用多个DCache模块导致耗时敏感，几十毫秒延迟的增加就可能导致上游接口调用超时；
4. 账号核心数据不能容忍数据丢失；

结合dbproxysvc存在的问题和账号服务访问DCache数据的特点，思考应该设计怎样的系统来兼顾性能、可用性、成本，并提出设计目标。

## 二、设计目标

1. 提供高性能存储访问解决方案，降低成本。
2. 同时支持TAF、HTTP、TRPC访问接口，兼容新老服务。
3. 确保数据安全，数据上云完成前每个步骤都要可回滚。
4. 可快速无损扩容，不出现性能瓶颈。
5. 提供主从热备+冷备，高可靠，支持定点回档。 
6. 无需业务关注容量，安全，监控。

## 三、难点

1. 非传统意义上的数据上云，除数据资产迁移到云上数据库外，还要自研一套数据代理服务替代DCache并兼容DCache协议，并达成上述设计目标。
2. DCache情况复杂，账号相关DCache模块较多总计135个，其中55个有流量确认需要迁移，剩余80个无流量，需要调查验证后进行下线。
3. 某些DCache模块有外部依赖，有10个模块 其他部门业务 也在共用，迁移过程不能影响 其他部门的业务。
4. 涉及账号服务较多，历史背景复杂，目前识别到的有23个账号服务需要参与数据上云改造。
5. DCache采用云下TDSQL数据库。经咨询，腾讯云DTS服务不适用于迁移至云上数据库，故需自行制定迁移方案。该方案需在确保业务流量持续读写、不停机的条件下，实现数据迁移及一致性校验。
6. 本身是逆向工程，要兼容历史背景，比如协议上要支持TAF、TRPC、HTTP，业务码要对齐DCache，并且接口性能不能有下降。
7. DCache的DB数据落后缓存5分钟（DCache实现方式决定，写入缓存成功就返回，5分钟后异步写DB）缓存数据是最新的但不全。因此数据迁移要同时兼顾DB数据和缓存中的最新数据，增加了迁移的难度。
8. DCache自身数据库性能较差，迁出数据时如果速度太快导致CPU使用过高会引起超时影响线上，速度太慢面对几百个GB的超大表迁移耗时难以接受，需要找到合理阈值。
9. 需要接入新的数据代理层服务，TAF调用改为TRPC，改造范围比较广，接入成本较高。
10. 一个DCache模块可能同时最多被六个账号服务使用，需要6个账号服务配合修改上线，涉及多个负责人，增加项目管理和信息同步难度。

## 四、落地方案

落地方案从以下几个方面展开介绍：语言和框架选择、云数据库选择、架构设计、接口和缓存系统设计（兼容DCache协议）、数据迁移方案、迁移流程和数据安全。

### 1、语言和框架选择

数据代理层服务为IO密集型，Go语言多协程相较于Java多线程具有先天优势。故考虑采用Go语言实现该服务，并已进行调研及压测分析。

**硬件：**4c8g pod节点，母机类型`S5.LARGE8`

**代码：**自定义空接口，无任何具体业务逻辑。请求100字节，返回61字节。

| **语言+框架**       | **最大QPS** |
| :------------------ | :---------- |
| Go + TRPC           | 40.08k      |
| Java + 内部自研框架 | 6.29k       |
| Java + Spring       | 14.27k      |

经过压测，我们发现基于 Java+自研框架 的dbproxysvc存在拦截器、日志打印及JSON序列化等业务逻辑繁重的问题，导致最大QPS仅为6.29k。即便采用Java+Spring框架，最大QPS也仅能达到14.27k。相比之下，Go+TRPC框架的最大QPS可达40.08k。因此，我们最终决定采用Go+TRPC方案以提升性能。

上述只是对空接口压测的理论值，因为目前也完成了大部分账号核心DCache上云，举一个实际对比的例子：

上云迁移之前dbproxysvc（Java+自研框架）承载 XxxAppAccount 消耗了180-200个4c8g pod，且高峰期偶现超时。

新开发的dbproxy-go（Go+TRPC），承载 XxxAppAccount 只消耗20-30个 4c8g pod,且高峰期耗时稳定。

确定dbproxy-go无性能问题后，后来接入了北极星、TAF主控以提供TRPC、TAF、HTTP的请求格式支持，兼容新老业务场景。

之后分别接入了galileo、cls做服务监控，接入七彩石做服务配置，接入消息队列做失败重试，形成目前架构。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261659093.png" alt="image-20250826165908963" style="zoom:50%;" />

### 2、云数据库选择

在上云事项开始前， XxxAppAccount 已经使用dbproxysvc上云。使用TDSQL作为持久化DB，Redis用作数据缓存。

考虑到DCache本身持久存储也是使用TDSQL，缓存是自研的DCache缓存。那么我们使用TDSQL和通用Redis作为数据存储替代方案与之非常相似，方案比较合理也是业界常用方案。

#### TDSQL集群

配置信息、可用性信息、架构图如下。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261700872.png" alt="image-20250826170004807" style="zoom: 33%;" />

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261700365.png" alt="image-20250826170034289" style="zoom:50%;" />

使用两个TDSQL实例组成TDSQL集群，其中上海实例为主实例，支持读写。广州实例是只读、灾备实例提供灾备和跨地区读加速能力。

部署方案上分上海、广州两地部署，上海4区、上海6区、广州4区、广州6区，四中心部署。

数据的写入只能通过上海主实例的master，之后强同步写入上海主实例的slave，异步写入到广州实例的master和slave，这里跨地区写入时延一般小于一秒。账号业务有个别场景数据一致性要求高，此类请求只能强制读上海实例，不能读广州实例。

实例架构方面，使用4分片，24c64g配置，理论吞吐量6w tps可以满足账号业务需求。基于可用性角度考虑，使用一主一备方案，如果实例的master挂了，服务HA检查发现后会将slave提升为master，无需业务侧关心。每个实例均自带冷备中心，除非上海广州大区机房同时遭受不可抗力损毁，否则都能保证数据安全。

**配置不够用怎么办？**

通过调整分片配置或增加分片的方式调整配额，调整后8小时内生效，需要预留调整时间。

**有无单点故障？**

主从架构可以规避单点故障，若主机故障，会触发HA策略，从机升为主机。

**有无其他问题？**

分布式数据库中，根据在建表时设定的分表键，系统将根据不同分表键自动分布数据到不同的物理分片中，但逻辑上仍然是一张完整的表。
在 TDSQL MySQL版 中，数据的切分通常就需要找到一个分表键（shardkey）以确定拆分维度，再采用某个字段求模（HASH）的方案进行分表，而计算 HASH 的某个字段就是 shardkey。 HASH 算法能够基本保证数据相对均匀地分散在不同的物理设备中。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261700290.png" alt="image-20250826170057205" style="zoom:50%;" />

因此会存在以下两个问题：

**1.建表要采用分表模式且保证分表键唯一，否则会导致分片使用率不平衡。**

DCache中多采用ukey+mkey联合主键，mkey设置为分表键，不能保证分表键唯一。会有分片不均匀问题。进行实测发现实际比较均匀，可以接受。

**2.请求要带分表键，否则会引起全分片检索影响性能。**

实际对DCache查询绝大多数查询都带ukey，该问题可忽略。

#### **Redis集群**

实例基本信息、规格信息，架构图如下。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508271025989.png" alt="image-20250827102526826" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261701469.png" alt="image-20250826170130396" style="zoom:50%;" />

与TDSQL部署方案类似，使用两个TDSQL实例组成Redis集群。其中上海实例为主实例，支持读写。广州实例是只读、灾备实例提供灾备和跨地区读加速能力。

部署方案：上海、广州两地部署；上海4区、上海6区、广州4区、广州6区，四中心部署。

数据的写入只能通过上海主实例的master，写入后异步写入上海主实例的slave，使用Redis全球复制功能同步数据到广州实例的master和slave，全球复制时间延迟一般小于一秒。账号业务有个别场景数据一致性要求高，此类请求需要**强制读上海实例的master分区，这里与TDSQL略有不同。**

实例架构方面，使用12 分片/8GB/1 副本配置，总计96Gb内存，最大网络吞吐9216Mb/s目前满足需要。基于可用性角度考虑，使用一主一备方案，如果实例的master挂了，服务HA检查发现后会将slave提升为master，无需业务侧关心。每个实例均自带冷备中心，除非上海广州大区机房同时遭受不可抗力损毁，否则都能保证数据安全。

**如何解决常见缓存问题缓存一致性、缓存击穿、缓存雪崩、缓存污染？**

缓存一致性问题，使用`Cache-Aside方案`解决,下文展开介绍。

缓存击穿问题，对于热点数据，提前将其加载到缓存中，并定期刷新缓存。

缓存雪崩问题，设计随机过期时间，避免缓存同时过期。

缓存污染问题，限制缓存写入接口，强制要求设置合理过期时间。

### 3、架构设计

整体架构图如下。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261704311.png" alt="image-20250826170412209" style="zoom:50%;" />

整体可划分为dbproxy-go后端、TDSQL集群、Redis集群、DCache后端四部分组成。

- **dbproxy-go后端**：dbproxy-go后端分别在上海、广州两地部署，接入TAF主控（用于TAF请求寻址）、接入北极星（用于TRPC和HTTP请求寻址），兼容TAF、TRPC、HTTP三种请求模式。

  上海地区的dbproxy-go服务固定就近访问上海地区的TDSQL和Redis，广州地区的dbproxy-go服务读请求固定访问广州地区的TDSQL和Redis，写请求固定访问上海的TDSQL和Redis。无论TDSQL还是Redis，都只有上海实例支持写入。

- **TDSQL集群**：使用两个TDSQL实例组成TDSQL集群，其中上海实例为主实例，支持读写。广州实例是只读、灾备实例提供灾备和跨地区读加速能力。

  部署方案上分上海、广州两地部署，上海4区、上海6区、广州4区、广州6区，四中心部署。

  数据的写入只能通过上海主实例的master，之后强同步写入到上海主实例的slave，异步写入到广州实例的master和slave，跨地区写入时延一般小于一秒。账号业务有个别场景数据一致性要求高，此类请求只能强制读上海实例，不能读广州实例。

  基于可用性角度考虑，使用一主一备方案，如果实例的master挂了，服务HA检查发现后会将slave提升为master，无需业务侧关心。每个实例均自带冷备中心，除非上海广州大区机房同时遭受不可抗力损毁，否则都能保证数据安全。

- **Redis集群**：与TDSQL部署方案类似，使用两个TDSQL实例组成Redis集群。其中上海实例为主实例，支持读写。广州实例是只读、灾备实例提供灾备和跨地区读加速能力。

  部署方案：上海、广州两地部署；上海4区、上海6区、广州4区、广州6区，四中心部署。

  数据的写入只能通过上海主实例的master，写入后异步写入上海主实例的slave，使用Redis全球复制功能同步数据到广州实例的master和slave，全球复制时间延迟一般小于一秒。账号业务有个别场景数据一致性要求高，此类请求需要强制读上海实例的master分区，这里与TDSQL略有不同。

  可用性设计，与TDSQL相同，使用一主一备方案，如果实例的master挂了，服务HA检查发现后会将slave提升为master，无需业务侧关心。每个实例均自带冷备中心，除非上海广州大区机房同时遭受不可抗力损毁，否则都能保证数据安全。

- **DCache 服务**：完全上云之前，dbproxy-go要先作为DCache代理工作一段时间，所以也要接入。

 

**有无单点故障问题？**

**dbproxy-go服务大区崩溃**，如果因为网络、自然灾害或是自身服务问题等原因导致dbproxy-go上海地区全部挂掉。那么TAF主控和北极星会将上游流量全部调度到广州地区。会造成广州流量加倍，为了保证广州地区能抗住全部流量，调整了扩容上限确保能抗住两倍的流量。

**TDSQL备分区崩溃（上海）**，因为强一致写，上海主分区写上海备份分区失败，写请求全局不可用，直到备分区恢复。不影响读。CP特性决定。

**TDSQL备分区崩溃（广州）**，会阻塞binlog同步，广州大区数据不一致窗口逐渐加大，直到备分区恢复，不影响全局读写。

**TDSQL主分区崩溃（上海）**，主分区崩溃，会被TDSQL的HA机制检测，会在1分钟之内发生主备切换，切换上海6区为主分区，上海5区恢复后成为备分区。这个过程写全局不可用，读不受影响，但是1分钟之内会有写入故障，之后自动恢复。

**TDSQL主分区崩溃（广州）**，影响binlog同步，广州大区不一致窗口逐渐增大直到恢复，不影响全局读写。

**TDSQL区域崩溃（广州）**，主备分区全挂，影响dbproxy-go广州地区的读，固定就近机制。可优化成如果广州不可用调用上海读。

**TDSQL区域崩溃（上海）**，主备分区全挂，影响全部的写，dbproxy-go上海的读。可优化成如果上海不可用调用广州读。

**REDIS备分区崩溃（上海、广州），**无影响

**REIDS主分区崩溃（广州）**，广州地区不一致窗口增大

**REIDS主分区崩溃（上海）**，影响全局写，不影响读。缓存命中率下降，若下降到90%以下，要小心DB挂掉。

**REIDS区域崩溃（广州）**，影响dbproxy-go广州的读，可优化读上海。

**REIDS区域崩溃（上海）**，影响全部写，dbproxy-go上海的读，可优化读广州。

### 4、接口和缓存系统设计

为了接口和缓存系统设计更加合理（需要兼容DCache协议），首先对已有的DCache方案和dbproxysvc方案进行了调研。

#### DCache方案

DCache方案中，数据写入Cache成功就返回，Cache会在5分钟之后才落库到DB，如果Cache挂了，会有丢失最近5分钟写入数据的风险。DCache方案原文中已标红。[DCache方案](https://km.woa.com/articles/show/302984?kmref=search&from_page=1&no=5)

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261706090.png" alt="image-20250826170559989" style="zoom:50%;" />



结合我们业务场景分析，我们认为这不满足我们业务对数据安全的要求。万一出现Cache挂掉丢失了近5分钟写入的数据。如果刚好丢失的是账号核心数据，可能会引起灾难性后果。

因此我们决定在设计新的数据代理服务时，改为数据同步写入DB后，再返回调用结果。这样就算DB挂了，调用写入接口的返回值会明确返回写入失败错误，不会出现返回写入成功但是数据丢失的情况。

#### dbproxysvc方案

dbproxysvc java版本的设计也参考了DCache，写缓存成功后就返回成功，最终没有继续沿用这个方案。因为篇幅原因，不阐述其完整方案，这里只阐述其中一个核心流程，说明其中存在的问题。dbproxysvc设计思路如下图所示。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261706956.png" alt="image-20250826170628847" style="zoom:50%;" />

写操作先尝试获取锁，如果失败要随机等待后重试，以此保证同一个key写入操作串行且不冲突。写到缓存投递mq后就返回写入成功，减少请求耗时，mq消息逐渐消化落库。

读操作若出现read redis miss和写操作同一个key并发的情况，若读操作读到到DB老数据，是有可能在写操作的write redis之后再write old redis造成脏缓存的。

为了解决这一问题，代码中write old redis加锁，期望是如果写操作write redis和读操作的write old redis并发时，丢弃调读操作的write old redis。

问题点：

1. 如果同时出现两个上游服务并发调用，同时写同一个key，这时不能保证mq中这个key两次写入的先后顺序，可能会出现两次DB写入落库后缓存数据与DB不一致。红线框给出修复方案。
2. 如图"出问题时间窗口"内进行了read old db动作，还是会写入脏缓存，红线框给出修复方案。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261706807.png" alt="image-20250826170652723" style="zoom:50%;" />

虽然方案最终未采用，但是经过修复后作为一种可行方案，分析了优缺点。

方案缺点：读写操作都需要有分布式锁。

方案优点：写入Redis就返回，写操作速度快，而且比较适和读多写少且缓存命中率高场景，写少则写锁可忽略影响。读多但缓存命中率高，读锁只发生在缓存miss情况下，缓存命中高之后，读锁影响不大。

#### **业界常用方案**

缓存可以提升性能、缓解数据库压力，但是使用缓存也会导致数据不一致性的问题。有三种经典的缓存模式：

- Cache-Aside Pattern 读建缓存，写删缓存，最常用方案。
- Read-Through/Write through 读建缓存，写同步双写，需要加锁。
- Write behind 读建缓存，写建缓存，异步写数据库，缓存和数据库的一致性不强，对一致性要求高的系统要谨慎使用，但适合频繁写入场景。

#### dbproxy-go方案

结合当前应用场景读多写少，读请求占比98%以上，并且吞吐量要求高的特点，选择`Cache-Aside Pattern`

下文结合逆向实现DCache的接口的过程，分析其中的缓存策略考虑。

这里简单铺垫DCache接口相关背景：DCache接口分一期和二期，一期较为简单不展开论述。这里主要介绍DCache二期的核心接口的实现。DCache二期数据格式，都包含一个主键mkey和联合主键ukey。主键+联合主键唯一确定一条数据库中记录。

**SelectMany接口**，接口的作用是通过一个主键查询数据记录，因为不限制联合主键，所以会查到多条记录。

isReadDCache是一个由七彩石控制的开关，如果开启就从DCache中读取，如果未开启就走云上DB读取。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261707576.png" alt="image-20250826170715471" style="zoom:40%;" />

**为什么没有使用redis缓存？**

因为SelectMany通常命中多行数据，如果把命中的多行数据一块放进缓存，那么缓存命名一般是moduleName_mkey。之后假如缓存的某一行数据有数值更新，除了更新自身行缓存（以moduleName_mkey_ukey为key的缓存），为了保险还要额外更新SelectMany建立的多行缓存（以moduleName_mkey的缓存），会多一个额外操作。而目前发现SelectMany接口调用量很少，所以暂时没有建立缓存。

**SelectOne接口**，接口作用是通过主键+联合主键查找数据，返回结果至多只有一条记录。这是线上调用最多的接口。

若开启isReadDCache七彩石开关就走DCache接口，否则从云上Redis检索，若检索到返回，检索不到再从云上DB检索，无论检索到与否都会为该key建立缓存或建立空缓存。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261708233.png" alt="image-20250826170823179" style="zoom:35%;" />

**云上DB检索不到的key为什么还需要建立空缓存？**

如果不建立缓存，并且此类请求较多，会有缓存击穿问题。

**异步redis.insert是否有一致性问题？**

会有，但是无锁模式下无法避免，就算单节点保证了，也无法阻止其他pod的并发修改。

例如，db.select读出一个key1-val1的同时，刚好其他线程写入DB一个key1-val2。

redis.insert建立key1-val1，而DB变成key1-val2，会有数据不一致问题。这个问题可以通过**延迟双删**解决，在短暂不一致后建立的脏缓存会被删除，下文中介绍延迟双删。

**为什么读建缓存，而不是在Insert和Update这种写操作的时候建立或更新缓存？**

若写操作建缓存，如图所示的场景，最终缓存写入线程A的内容，数据库写入线程B的内容导致数据不一致。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261708718.png" alt="image-20250826170855594" style="zoom:50%;" />

**Insert接口或Update接口**，接口作用是插入或更新一条数据。

如果打开isWriteDCache七彩石开关，先执行DCache写入，再执行DB写入，是个双写过程。否则只写入DB不写入Dcache。之后判断isWriteRedis，如果为true，则进行延迟双删操作后结束，否则直接结束。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261709925.png" alt="image-20250826170931825" style="zoom:40%;" />

**为什么阻塞写据库而不用消息队列？**

消息队列好处是可立即返回给用户成功，后续异步消费写DB。缺点是若消息队列挂掉永久丢失写入数据。

阻塞写的好处是阻塞写入后告诉用户写入结果，缺点调用耗时略高，但是账号服务是读多写少的场景且不能容忍数据丢失，所以使用该方案。

**为什么写操作要先写数据库再删缓存？**

若写数据库在最后，可能会出现以下问题。

1.del cache之后，线程A的write db拖延到线程B的2.cache miss 3.read db 4.set cache之后，最后线程A执行5.write db。

最终结果是数据库为新数据，缓存中为老数据。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261709349.png" alt="image-20250826170952306" style="zoom:50%;" />



**为什么要延时双删？**

是因为就算使用了上述写操作先写数据库再删缓存方案，也只能解决上图中缓存没过期情况下由写操作del cache引发的数据不一致问题，但是无法解决缓存自然过期情况下的数据一致性问题，即上文**SelectOne接口**中描述的问题。

**缓存自然过期情况下的数据一致性问题**：若只删除一次缓存，假如读操作缓存过期导致read cache miss + read old db，之后发生写操作带来的write new db + del cache，最后write old cache，仍然会有db与缓存不一致问题。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261710219.png" alt="image-20250826171006146" style="zoom:40%;" />

在读多写少，缓存命中率高的背景下，read cache miss发生概率较低，并且read cache miss同时发生写操作的概率更低，因此经过**写操作先写数据库再删缓存**优化后，可以减少出现数据一致性问题的概率，但是无法规避。

为了从根本上规避解决，需要写操作write new db + del cache之后延迟一段时间再次del cache来解决。

**延时一般多久？**

如果DB的操作都是强一致的，那么如果要发生上图问题，只需延迟超过read old db到write old cache之间的间隔即可，但是一般这个延迟时间=整个读操作耗时+几百毫秒冗余。

为了确保读请求结束，写请求可以删除读请求可能带来的缓存脏数据。考虑到db和redis的主从同步，延迟双删的延迟时间=整个读操作耗时+DB同步延迟+几百毫秒冗余。

**延时双删失败怎么办？**

第二次删除若失败，可能导致缓存与DB不同步，为了避免这种情况发生，需要新增重试策略。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261710054.png" alt="image-20250826171028971" style="zoom:50%;" />

**双写过程发生局部写入失败怎么办？**

为了方案简化，DCache的写入和云上DB的写入没有事务保证，可能会出现写入DCache成功而写入DB不成功的情况，这种情况会打印trace记录cls，是可追溯的。

**多地部署TDSQL和Redis需要更多考虑**

因为TDSQL的binlog主从同步是异步的，可能会引入数据一致性问题。具体来说，如果主从同步的时间窗口内，有读操作缓存未命中读到从库数据，随后从库更新为新数据，造成缓存和DB的数据不一致，本质上还是延迟双删面临的问题。为了解决这个问题，提出了三种解决方案：

**方案一**

使用从db binlog更新记录来触发延迟双删。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261711151.png" alt="image-20250826171140101" style="zoom:50%;" />

**使用方案一的消息队列方案是否还需要延迟双删？**

如果在下图窗口期同时完成：写从DB，mq同步和删除redis缓存，是有可能出现建立脏缓存问题的。但是实际情况下，这个窗口期是读完db到写redis的间隔，窗口期极短。远小于写从db+binlog同步mq+删除redis缓存所需的诗句，可以有效删除脏缓存。没有必要再次双删。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261712301.png" alt="image-20250826171204254" style="zoom:50%;" />

**方案二**

读操作若cache miss，若读从库，不能建缓存，而是内部触发一次主库读（辅助建立缓存）。

这种方案价值不大，导致从库读访问率为0%，相当于移除了从db就近访问功能。

**方案三**

延迟双删的第二次删除和第一次删除的时间间隔适当增加，确保这个时间间隔>DB主备同步时间+读业务逻辑数据的耗时+几百毫秒冗余 即可。**目前线上是方案三。**

#### 方案总结

1. 使用Cache-Aside Pattern，读建缓存，写删缓存。
2. SelectMany接口没有Redis使用缓存，直接命中数据库，目前该接口使用量较小，暂无问题。
3. 写删缓存一定要先写数据库再删缓存。
4. 延迟双删时间间隔要考虑主备同步。
5. 若延迟双删第二次删除失败，需要消息队列反复删除，直到成功。

### 5、数据迁移方案

DCache的数据源在云下TDSQL数据库,经过咨询不能使用腾讯云DTO工具将数据导出到云上DB，因此需要自己设计脚本进行数据迁移。而且就算可以使用腾讯云DTO工具将数据导出到云上，也不可避免的需要设计脚本补偿和校验，下文会说明原因。

以一个DCache模块上云的流程说明数据迁移的问题：

1. 数据迁移前会先复制DCache数据库的建表语句到云上数据库进行建表，确保字段和格式保持不变。
2. 修改七彩石配置，将dbproxy-go中该模块访问模式配置为DCache代理模式（读写DCache并且写云上DB）同时打开迁移锁开关，迁移锁在下文中介绍其作用。
3. 数据上云代码开发，确认调用该DCache模块的所有服务都完成dbproxy-go上云改造，并且确保服务全量上线。此时dbproxy-go是Dcache代理，额外双写云上DB。
4. 运行迁移脚本进行数据迁移。

经过前四部操作，实际情况如图所示。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261712059.png" alt="image-20250826171249966" style="zoom:50%;" />

如图所示，**迁移目标是将全量Dcache Cache数据+全量Dcache DB数据迁移进云上DB。**

首先，dbproxy-go的双写机制会保证写入操作insert、update、delete同步写入云上DB和DCache Cache，可以实时迁移**热数据（5分钟之内的数据，图中标红）**。这个机制会保证热数据insert和热数据delete全量迁移，**热数据update不一定**，因为初始态云上DB为空不存在要update的记录导致无法update。

其次，发生数据写入操作时，先同步写入Dcache的Cache和云上DB，再异步5分钟后写入Dcache，这个机制会造成Dcache DB和Dcache Cache数据不一致。如果遍历Dcache Cache的数据进行迁移，能拿到最新的数据，但是老数据不全；如果遍历DCache DB进行数据迁移，能拿到全量老数据，但是没有近5分钟新数据。为此决定采用从**DCache DB迁移数据 + DCache Cache修正补偿的方案**进行数据迁移。

**为什么要先上线代理服务，全量打开双写后再跑脚本？**

这样做的目的是避免产生脏数据。如果先跑脚本迁移数据，再开双写。迁移脚本跑完到开启双写中间时间窗口若发生了数据删除操作，云上数据库感知不到也删不掉，云上DB中会产生已被DCache删除的脏数据。

**迁移脚本如何设计？**

首先，迁移脚本会逐条遍历DCache的数据库。实际遍历的内容图中大括号已经标识，可以看到缺少近5分钟的数据。这并非问题，在数据迁移脚本开始执行之前，近5分钟的数据通过双写已经在实时写入云上DB。

但是DCache数据库中的数据实际上是落后DCache Cache的，要考虑使用DCache Cache数据进行修正。

修正过程如下，依次分析如何设计对比和修正策略保证以下三个场景下的数据一致性。

**5分钟之内insert缺失**，不必关注，已经通过双写机制写入云上DB。

**5分钟之内update缺失**，在迁移每一行数据之前，对比DB和DCahce Cache中差异，如果一致直接迁移，如果不一致以DCache Cache为准进行迁移。

**5分钟之内delete缺失**，在迁移每一行数据之前，对比DB和DCahce Cache中差异，如果Dcache Cache中不存在说明近5分钟发生删除，不迁移该行，否则迁移。

合并三个场景操作后的等效简化操作就是，**从DCache的DB取一条数据，在DCahce Cache查是否存在，若存在则使用DCache Cache的数据写入云上DB，否则跳过这条数据。**

经过上述过程后，基本的数据迁移流程已经具备，不过截止目前还是会存在两个问题，

1. **5分钟之内的update若key在云上DB不存在，无法写入成功的问题**

​       解决方案是再次跑脚本，第二次跑脚本时云上DB一定有全量的key，第二次跑脚本不会出现该问题。

2. **如果更新某个key和迁移某个key并发，如果双写先成功，迁移后成功，会迁移老数据到云上DB**

​       设计一个分布式迁移锁，某个key写云上DB前加锁，写入成功前不允许迁移该key，迁移脚本重试获取锁成功后才能继续迁移改key确保迁移最近数据到云上DB。

接下来结合迁移脚本使用规则来阐述迁移脚本的实现。

迁移脚本参数介绍。

| **参数名** | **是否必填** | **含义**                                            |
| :--------- | :----------- | :-------------------------------------------------- |
| batchSize  | 是           | 迁移总批次数                                        |
| batchNum   | 是           | 每批次迁移数量                                      |
| lastIter   | 是           | 从哪个主键开始迁移，支持断点续传。如果从头开始填写0 |
| routineNum | 是           | 协程数量                                            |
| yamlName   | 是           | 源库目标库连接信息、模块名称和字段信息              |
| isTestEnv  | 是           | true-测试环境 false-生产环境                        |

代码解释

代码改写

```
Usage:<exec> <yamlName> <isTestEnv> <batchSize> <batchNum> <routineNum> <lastIter>

./migrate wecar_inverse_query_new.yaml false 300 10000 2000 0
```

迁移脚本整体设计如下图。

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261716738.png" alt="image-20250826171600661" style="zoom:50%;" />

首先按照预设的isTestEnv判断迁移目标是测试还是生产环境，然后从yamlName指定的yaml文件读取源库、目标库的信息，模块名称和主键、联合主键信息。

读取系统时间判断如果不是早晚高峰就开始数据迁移，如果是早晚高峰会等待高峰后继续。

按照预设的BatchSize从BatchIter开始逐批次开启协程迁移。

一个数据迁移协程内的操作：

1. 数据迁移协程中会逐行读取DB内容进行迁移，迁移每一行时，会先以migrate_moduleName_mkey_ukey的格式尝试加锁，如果成功继续，否则以一秒间隔重试3次，如果成功则继续，若3次失败则记录error并跳过该key继续下一个key的迁移。

**另外一处加锁在dbproxy-go的insert和update接口数据写入DB时，脚本加锁目的是为了迁移前判断当前key是否正在通过dbproxy-go并发写入。如果有这种情况需要等待dbproxy-go的写入完成后再继续该key的迁移，避免写入脏数据。**

2. 使用当前迁移行的主键联合主键作为参数调用DCache接口从DCache Cache中获取该行最新数据。
3. 如果DCache接口可以查到数据，使用insert into … on duplicate将查到的DCache数据插入云上DB。此语句的好处是从执行结果可以知道是新增、更新、还是重复，为统计工作提供便利。
4. 进行该条数据写入结果统计，即更新当前协程内部计数变量insert、update、duplicate、error中其一。
5. 循环1-4步骤完成当前批次数据迁移，之后统计当前协程内部计数变量，以线程安全变量的形式提交给主协程统计。

主协程负责分派迁移任务和回收迁移结果，分派任务完成且所有协程结束后，汇总迁移结果并输出。

 

### 6、上云流程和数据安全

一个DCache模块可能同时最多被6个账号服务使用，上云改造需要6个账号服务配合修改上线，涉及多个负责人。同时根据开发进展，要在适当的节点跑迁移脚本进行数据迁移，在合适的节点从Dcache读写切到云上DB读写。流程较多需要规范化避免出错。因此输出上云流程文档介绍这个过程。



## 五、方案整理

**DB选择：**

1. DB使用了TDSQL的**主从架构**，此外还调查**RAFT架构**，但是咨询TDSQL官方目前RAFT架构还不支持异地灾备，决定继续使用主从架构。
2. **开启强一致**。**开启异地灾备，两地部署。**异地带来的一致性降低问题我们通过代码解决。
3. **如果出现主分区或备分区之一故障，可以自动恢复。**但是出现主备同时挂掉会引起线上故障，只能等待故障恢复。
4. **支持同时接入多组DB，除了TDSQL，也可扩展MYSQL**，只需要七彩石配置即可，无需修改代码。

**Redis选择：**

1. **Redis使用分片集群模式，开启读写分离。**
2. 开启**全球复制下的主从同步模式，两地部署，不采用多主模式。**
3. HA 系统监测到节点故障后，会将请求切换到从节点，可认为**无单点故障。**

**缓存架构设计：**

1. 使用**Cache-Aside Pattern，读建缓存，写删缓存。**
2. **SelectMany接口不能redis使用缓存**，直接命中数据库。
3. 写删缓存一定要**先写数据库再删缓存。**
4. 使用**延迟双删**，目前删除间隔1秒，**双删失败消息队列重试**。

**强一致性场景兼容设计：**

1. 因只有少量个别场景需要强一致，写完立马读，因此在整体方案为最终一致的情况下，支持临时提升到强一致。
2. 读接口增加强一致标志位参数，**若读请求带强一致参数，强制读DB主分区或Redis主分区达成。**

**语言和架构的选择：**

1. **Go语言协程+TRPC**处理，减少等IO的资源占用的方式提高吞吐量。
2. 自定义拦截器，**拦截panic格式化错误码和回包。**
3. **业务层异常直接抛panic**，会被拦截器捕获，不需要跨层传递业务码。
4. **接入伽利略，接入CLS**。
5. **支持多数据库实例、多Redis实例，通过七彩石配置**。

**数据迁移：**

1. **数据迁移脚本执行前开启双写，保证增量数据迁移**。
2. 数据迁移脚本执行第一次，**迁移存量数据，可能遗漏极个别update数据**。
3. 数据迁移脚本执行第二次，**进行校验**，可以通过结果分析出第一次迁移有无遗漏极个别update数据或是否存在其他问题。
4. 如果第二次迁移结果duplicate等于总数，insert、update、error均为0，则校验成功无需进行第三次迁移。否则分析原因继续第三次迁移直至无误。







------







# 数据上云现状

DCache模块总计135个，其中账号侧服务有代码调用的共计55个。

为了更好的阐述数据上云事项，每个DCache模块的数据上云工作分为了四个阶段：

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261651032.png" alt="image-20250826165144971" style="zoom:50%;" />

- **初始状态：**数据上云之前DCache模块现状。
- **DCache代理阶段，读写DCache+写云上DB：**在DCache模块代码开发之前，会预先在七彩石配置中为该Dcahce模块配置为读写DCache+写云上DB状态。当调用该Dcache模块的服务都完成上云改造并全量上线后，这时的dbproxy-go工作在DCache代理模式下，并且额外写云上DB。
- **移除DCache代理，读写云上DB+写DCache**：达到阶段一之后可以跑脚本进行数据迁移，数据迁移完成后，通过修改七彩石配置达到阶段二，这个过程不需要修改代码。达成阶段二之后，DCache模块已经完成上云，只是额外写DCache做数据安全备份。
- **DCache下线，读写DB，DCache下线：**在阶段二的基础上观察至少一个月没有问题，通过修改七彩石配置接口达到阶段三，之后可以进行DCache下线操作。







------







# 数据上云流程













------







# 预备面试题

## 1、为什么数据代理层是IO密集型？

**IO 密集型（I/O-bound）** 的核心定义：指程序的执行效率主要受限于**输入 / 输出（I/O）操作的速度**（如网络传输、磁盘读写、数据库查询等），而非 CPU 的计算能力 —— 即 CPU 大部分时间在 “等待” I/O 操作完成，而非高速处理计算逻辑。

数据代理层的核心职责是 **“中转、协调数据流转”**，而非复杂的业务计算。其工作流程中，几乎所有核心操作都依赖 I/O，具体场景如下：

- 数据代理层本质是 **“数据的中间传递者”**，需频繁与上下游服务通过网络交互：
  - **接收请求**：网络 I/O，等待请求包传输
  - **转发请求**：后端的数据库、缓存（Redis、文件存储（S3）或其他微服务（网络 I/O，等待后端响应）
  - **返回结果**：后端返回的数据整理后，回传给前端 / 业务层（再次网络 I/O）
- 依赖磁盘 I/O：临时数据缓存、日志记录
- 几乎无复杂计算

`除了 IO 密集型，还有哪些类型的程序？`

| 类型           | 核心瓶颈           | 典型场景                                                     | CPU 利用率特点                                       |
| :------------- | ------------------ | ------------------------------------------------------------ | ---------------------------------------------------- |
| **IO 密集型**  | 输入 / 输出（I/O） | 数据代理层、API 网关、Web 服务（如 Flask/Django）、数据库查询、文件传输 | 低（大部分时间等待 I/O）                             |
| **CPU 密集型** | 中央处理器（CPU）  | 科学计算（如矩阵运算、数值模拟）、数据加密 / 解密（如 RSA）、图像视频处理（如 PS 滤镜）、机器学习训练（如 CNN 反向传播） | 高（接近 100%，CPU 满负荷运行）                      |
| **内存密集型** | 内存（RAM）        | 缓存服务（如 Redis 集群）、大数据处理（如 Spark 内存计算）、实时数据分析（如 Flink 状态存储） | 内存占用高（接近或达到物理内存上限），CPU 利用率中等 |

## 2、Mysql的集群架构是什么？

mysql部署架构采用的是：主备同步（一主多从） + 读写分离 + 异地容灾；

机器分别部署在上海和广州集群中，两个集群都存在主节点（master）和从节点（slave），分别部署2个实例；

并且主节点（master）和从节点（slave）之间数据同步采用 `强同步`，意味着主节点写入数据后，需要确保从节点也成功写入数据，才会向客户端返回写入成功的响应。这种同步方式可以保证主从节点数据的强一致性， 降低了数据丢失的风险，但是可能会对写入性能产生一定的影响，因为需要等待从节点的确认；

两个集群之间数据同步采用 `binlog` 异步同步的方式，这可以保证在异地的两个实例之间数据可以相互复制，以便在进行异地切换时，数据能够尽量保持一致。虽然是异步同步可能会存在短暂的数据延迟，但在保证系统可用性和数据一致性之间做了一定的权衡；

只上海的master节点作为写节点，其他都作为读节点，以达到读写分离的效果，因为98%请求都是读请求；

<img src="https://raw.githubusercontent.com/arminxu-coding/image/main/2025/202508261700365.png" alt="image-20250826170034289" style="zoom:30%;" />

## 3、假设主Master节点挂了怎么办？

**主从切换机制**：在具备主从架构的数据库系统中，一般会有高可用（HA，High Availability）管理组件 来监控主节点状态。当主 master 写入节点挂掉后，HA 组件会通过心跳检测等机制感知到主节点故障，随后会执行主从切换操作，将一个从节点（slave）提升为新的主节点。

**proxy 层调整**：在主从切换完成后，proxy层需要感知到主节点的变化，重新更新内部的路由规则。原本指向故障主节点的写请求，会被重新定向到新提升的主节点上；读请求则依然可以根据配置，继续分发到从节点上（由于有多个从节点，还涉及负载均衡策略，比如根据从节点的负载情况、连接数等进行请求分配 ）。

> todo: 这里需要查看 dbproxy-go 源码，看看具体的实现；

由于存在异地部署（上海和广州实例），在完成主从节点切换之后，还会涉及到异地数据的同步和协调，需要进行数据一致性的校验和修复。

并且这里到底会切换哪个从节点作为新的主节点会有 **HA组件** 进行决策，可能会是本地域切换、也可能会跨地域切换，一般会有以下情况：

- **节点健康状态**：HA 管理组件会通过心跳检测、SQL 连接测试等多种方式，持续监控各个 slave 节点的健康状况。
- **复制延迟情况**：会优先选择复制延迟最小的 slave 节点。因为复制延迟越小，说明该节点的数据和原 master 节点的数据差异越小，提升为主节点后能最大程度地保证数据一致性。HA 组件通常会记录每个 slave 节点的延迟信息（比如通过对比主从节点的日志位置、事务提交时间戳等），在选择时，会从延迟最低的节点中进一步筛选。
- **节点性能指标**：包括 CPU 使用率、内存使用率、磁盘 I/O 性能等。
- 也会跟具体的配置策略有关系，在 腾讯云console中，是可以进行自定义配置对应的策略的，可以设置权重、地理位置便好等。



